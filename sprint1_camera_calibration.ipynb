{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sprint 1: Camera Calibration Module\n",
    "\n",
    "**Project:** Road Defect Detection System (PROSIT 1)  \n",
    "**Team Members:**\n",
    "- Naa Lamle Boye\n",
    "- Thomas Kojo Quarshie\n",
    "- Chelsea Owusu\n",
    "- Elijah Boateng\n",
    "\n",
    "**Date:** 2024\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook performs camera calibration to determine the intrinsic parameters (camera matrix K) and distortion coefficients of the smartphone camera used for road defect detection.\n",
    "\n",
    "**What this notebook achieves:**\n",
    "- Extracts checkerboard corner points from calibration videos\n",
    "- Calculates camera intrinsic matrix (focal length, principal point)\n",
    "- Calculates distortion coefficients (radial and tangential distortion)\n",
    "- Saves calibration data for use in subsequent processing steps\n",
    "- Tests calibration by undistorting sample images\n",
    "\n",
    "**Output:** `camera_calib.npz` file containing calibration parameters (mtx, dist, rvecs, tvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in ./venv/lib/python3.14/site-packages (4.13.0.92)\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.14/site-packages (2.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in ./venv/lib/python3.14/site-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./venv/lib/python3.14/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in ./venv/lib/python3.14/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./venv/lib/python3.14/site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./venv/lib/python3.14/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in ./venv/lib/python3.14/site-packages (from matplotlib) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in ./venv/lib/python3.14/site-packages (from matplotlib) (26.0)\n",
      "Requirement already satisfied: pillow>=8 in ./venv/lib/python3.14/site-packages (from matplotlib) (12.1.0)\n",
      "Requirement already satisfied: pyparsing>=3 in ./venv/lib/python3.14/site-packages (from matplotlib) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./venv/lib/python3.14/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.14/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Setup and Parameters\n",
    "\n",
    "Define checkerboard dimensions and calibration settings. The checkerboard pattern is used because it provides easily detectable corner points with known 3D coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "# Number of INTERNAL corners (width, height)\n",
    "# For a 9x6 square board, there are 8x5 internal corners.\n",
    "CHECKERBOARD = (8, 5) \n",
    "\n",
    "# Termination criteria for sub-pixel accuracy\n",
    "# We stop when either the accuracy reaches 0.001 or 30 iterations are met.\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(7,4,0)\n",
    "# These represent the coordinates of the corners in the real world.\n",
    "# Z=0 because the checkerboard is flat (planar)\n",
    "objp = np.zeros((CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[:, :2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "\n",
    "# Arrays to store vectors from all calibration images\n",
    "objpoints = []  # 3D point in real world space\n",
    "imgpoints = []  # 2D points in image plane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Calibration Video Files\n",
    "\n",
    "Specify the paths to calibration videos. These videos contain the checkerboard pattern captured from different angles and distances to ensure robust calibration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = [\n",
    "    'checkerboard/IMG_1059.MOV', \n",
    "    'checkerboard/IMG_1060.MOV', \n",
    "    'checkerboard/IMG_1061.MOV', \n",
    "    'checkerboard/IMG_1062.MOV'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Extract Corner Points from Videos\n",
    "\n",
    "This is the main data collection step. We process frames from each calibration video, detect checkerboard corners, and refine corner positions to sub-pixel accuracy. We sample every 3rd frame to balance between data diversity and computational efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: checkerboard/IMG_1059.MOV\n",
      "Processing: checkerboard/IMG_1060.MOV\n",
      "Processing: checkerboard/IMG_1061.MOV\n",
      "Processing: checkerboard/IMG_1062.MOV\n",
      "\n",
      "Total valid frames collected across all videos: 30\n"
     ]
    }
   ],
   "source": [
    "found_count = 0\n",
    "sample_rate = 3  # Process every 3rd frame to balance diversity and speed\n",
    "image_size = None\n",
    "\n",
    "for video_path in video_files:\n",
    "    print(f\"Processing: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    frame_in_video = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_in_video % sample_rate == 0:\n",
    "            # Convert to grayscale (corner detection works on grayscale)\n",
    "            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            \n",
    "            # Store image size (needed for calibration, same for all frames)\n",
    "            if image_size is None:\n",
    "                image_size = gray.shape[::-1]  # (width, height)\n",
    "\n",
    "            # Find the checkerboard corners\n",
    "            # ADAPTIVE_THRESH handles varying lighting conditions\n",
    "            # NORMALIZE_IMAGE normalizes the image before detection\n",
    "            # FAST_CHECK speeds up processing for frames where board isn't visible\n",
    "            ret_corners, corners = cv2.findChessboardCorners(\n",
    "                gray, CHECKERBOARD, \n",
    "                cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_NORMALIZE_IMAGE + cv2.CALIB_CB_FAST_CHECK\n",
    "            )\n",
    "\n",
    "            if ret_corners:\n",
    "                # Refine corner positions to sub-pixel accuracy\n",
    "                # This improves calibration quality\n",
    "                corners2 = cv2.cornerSubPix(gray, corners, (11, 11), (-1, -1), criteria)\n",
    "                \n",
    "                # Store the point correspondences\n",
    "                objpoints.append(objp)  # Same 3D points for all images\n",
    "                imgpoints.append(corners2)  # Refined 2D points\n",
    "                found_count += 1\n",
    "        \n",
    "        frame_in_video += 1\n",
    "    cap.release()\n",
    "\n",
    "print(f\"\\nTotal valid frames collected across all videos: {found_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Perform Camera Calibration\n",
    "\n",
    "Using the collected point correspondences, we calculate the camera intrinsic matrix and distortion coefficients. The RMS reprojection error indicates calibration quality (lower is better, ideally < 1.0 pixel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the camera calibration\n",
    "# ret: the RMS re-projection error (lower is better, ideally < 1.0)\n",
    "# mtx: Camera Matrix (contains focal length and principal point)\n",
    "# dist: Distortion Coefficients (models lens distortion)\n",
    "# rvecs / tvecs: Rotation and Translation vectors (extrinsic parameters for each image)\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, image_size, None, None)\n",
    "\n",
    "print(\"--- Calibration Results ---\")\n",
    "print(f\"\\nRe-projection Error: {ret:.4f}\")\n",
    "print(\"\\nCamera Matrix (K):\")\n",
    "print(mtx)\n",
    "print(\"\\nDistortion Coefficients (d):\")\n",
    "print(dist)\n",
    "\n",
    "# Save these results so you don't have to re-run the video processing again\n",
    "np.savez(\"camera_calib.npz\", mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)\n",
    "print(\"\\nCalibration data saved to 'camera_calib.npz'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test Calibration by Undistorting an Image\n",
    "\n",
    "We verify our calibration works by undistorting a sample frame. This removes lens distortion and should make straight lines appear straight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab a sample frame from the first calibration video\n",
    "cap = cv2.VideoCapture(video_files[0])\n",
    "ret, frame = cap.read()\n",
    "cap.release()\n",
    "\n",
    "if ret:\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # Refine the camera matrix \n",
    "    # alpha=0: zooms in to remove all black pixels (crops)\n",
    "    # alpha=1: keeps all pixels but leaves black edges where data is missing\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w, h), 1, (w, h))\n",
    "\n",
    "    # Apply undistortion to remove lens distortion\n",
    "    dst = cv2.undistort(frame, mtx, dist, None, newcameramtx)\n",
    "\n",
    "    # Crop the image based on the ROI (Region of Interest) to remove black edges\n",
    "    x, y, w_roi, h_roi = roi\n",
    "    dst_cropped = dst[y:y+h_roi, x:x+w_roi]\n",
    "\n",
    "    # Display the comparison\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(121), plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)), plt.title('Original (Distorted)')\n",
    "    plt.subplot(122), plt.imshow(cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)), plt.title('Undistorted')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Could not read frame.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
